{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join dataframes (business + reviews)\n",
    "## Yelp data\n",
    "* Joined the business and reviews data in dataframe and stored it in \"joined_3mReviews_df.p\"\n",
    "* Created the column of ['latest_3m_reviews'] which stores the latest 3 months reviews from the time we want to do prediction.\n",
    "* Updated columns ['review_count', 'latest_3m_reviews_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Import reviews dictionary and yelp_business dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BUS_PATH = \"data/processed/processed_bus_df.p\"\n",
    "bus_df = pd.read_pickle(BUS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'name', 'neighborhood', 'address', 'city', 'state',\n",
       "       'postal_code', 'latitude', 'longitude', 'stars', 'review_count',\n",
       "       'is_open', 'BikeParking', 'BusinessAcceptsBitcoin',\n",
       "       'BusinessAcceptsCreditCards', 'BusinessParking_garage',\n",
       "       'BusinessParking_street', 'BusinessParking_validated',\n",
       "       'BusinessParking_lot', 'BusinessParking_valet', 'DogsAllowed',\n",
       "       'RestaurantsPriceRange2', 'WheelchairAccessible', 'categories', 'hours',\n",
       "       'type', 'Alcohol', 'Ambience_romantic', 'Ambience_intimate',\n",
       "       'Ambience_classy', 'Ambience_hipster', 'Ambience_touristy',\n",
       "       'Ambience_trendy', 'Ambience_upscale', 'Ambience_casual', 'Caters',\n",
       "       'GoodForKids', 'GoodForMeal_dessert', 'GoodForMeal_latenight',\n",
       "       'GoodForMeal_lunch', 'GoodForMeal_dinner', 'GoodForMeal_breakfast',\n",
       "       'GoodForMeal_brunch', 'HasTV', 'NoiseLevel', 'OutdoorSeating',\n",
       "       'RestaurantsAttire', 'RestaurantsDelivery', 'RestaurantsGoodForGroups',\n",
       "       'RestaurantsReservations', 'RestaurantsTableService',\n",
       "       'RestaurantsTakeOut', 'WiFi', 'AcceptsInsurance', 'ByAppointmentOnly',\n",
       "       'HairSpecializesIn', 'Ambience_divey', 'DriveThru', 'attributes',\n",
       "       'BYOB', 'BYOBCorkage', 'Corkage', 'RestaurantsCounterService',\n",
       "       'BestNights_monday', 'BestNights_tuesday', 'BestNights_friday',\n",
       "       'BestNights_wednesday', 'BestNights_thursday', 'BestNights_sunday',\n",
       "       'BestNights_saturday', 'CoatCheck', 'GoodForDancing', 'HappyHour',\n",
       "       'Music_dj', 'Music_background_music', 'Music_no_music', 'Music_karaoke',\n",
       "       'Music_live', 'Music_video', 'Music_jukebox', 'Smoking', 'AgesAllowed',\n",
       "       'DietaryRestrictions', 'Open24Hours'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note: using workaround for issue 24658"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = \"/Users/xinpeilin/Documents/CS_Learning/Data_Mining/Project/review_cleaned_d.p\"\n",
    "\n",
    "class MacOSFile(object):\n",
    "\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "\n",
    "    def __getattr__(self, item):\n",
    "        return getattr(self.f, item)\n",
    "\n",
    "    def read(self, n):\n",
    "        # print(\"reading total_bytes=%s\" % n, flush=True)\n",
    "        if n >= (1 << 31):\n",
    "            buffer = bytearray(n)\n",
    "            idx = 0\n",
    "            while idx < n:\n",
    "                batch_size = min(n - idx, 1 << 31 - 1)\n",
    "                # print(\"reading bytes [%s,%s)...\" % (idx, idx + batch_size), end=\"\", flush=True)\n",
    "                buffer[idx:idx + batch_size] = self.f.read(batch_size)\n",
    "                # print(\"done.\", flush=True)\n",
    "                idx += batch_size\n",
    "            return buffer\n",
    "        return self.f.read(n)\n",
    "\n",
    "    def write(self, buffer):\n",
    "        n = len(buffer)\n",
    "        print(\"writing total_bytes=%s...\" % n, flush=True)\n",
    "        idx = 0\n",
    "        while idx < n:\n",
    "            batch_size = min(n - idx, 1 << 31 - 1)\n",
    "            print(\"writing bytes [%s, %s)... \" % (idx, idx + batch_size), end=\"\", flush=True)\n",
    "            self.f.write(buffer[idx:idx + batch_size])\n",
    "            print(\"done.\", flush=True)\n",
    "            idx += batch_size\n",
    "\n",
    "def pickle_dump(obj, file_path):\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        return pickle.dump(obj, MacOSFile(f), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def pickle_load(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return pickle.load(MacOSFile(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "review_d = pickle_load(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Create column ['reviews'] in bus_df, having only the latest 3 months reviews. Update bus_df['review_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "ThreeMonths = 7776000 # 90 days in second\n",
    "FourMonths = 120*24*60*60\n",
    "\n",
    "def get_time(date_str):\n",
    "    return time.mktime(datetime.datetime.strptime(date_str, \"%Y-%m-%d\").timetuple())\n",
    "\n",
    "#input dictionary and a string of bus_id, output a date string of the last review \n",
    "def last_review_date(review_dict, bus_id):\n",
    "    MIN_TIME = \"2000-01-01\"\n",
    "    last_date = MIN_TIME\n",
    "    if bus_id not in review_dict:\n",
    "        return \"error: not found\"\n",
    "    for key, value in review_dict[bus_id].items():\n",
    "        if get_time(last_date) < get_time(key):\n",
    "            last_date = key\n",
    "    return last_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "--6MefnULPED_I942VcFNA      22\n",
       "--9e1ONYQuAa-CB_Rrw7Tw    1280\n",
       "--DaPTJW3-tB1vP-PfdTEg      29\n",
       "--FBCX-N37CMYDfs790Bnw      84\n",
       "--GM_ORV2cYS-h38DSaCLw       5\n",
       "Name: review_count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#instances_num = 48493\n",
    "bus_df['latest_3m_reviews'] = \"\"\n",
    "bus_df['latest_3m_reviews_count'] = 0\n",
    "for index, row in bus_df.iterrows():\n",
    "    if row['business_id'] in review_d:\n",
    "        text = \"\"\n",
    "        review_num = 0\n",
    "        review_num_3m = 0\n",
    "        last_date = last_review_date(review_d, row['business_id'])\n",
    "        for key, value in review_d[row['business_id']].items():\n",
    "            for review in value:\n",
    "                review_num += 1\n",
    "                if get_time(key) > (get_time(last_date) - ThreeMonths):\n",
    "                    text = text + review + \" \"\n",
    "                    review_num_3m += 1\n",
    "        bus_df.loc[bus_df.business_id == row['business_id'], 'review_count'] = review_num\n",
    "        bus_df.loc[bus_df.business_id == row['business_id'], 'reviews'] = text\n",
    "        bus_df.loc[bus_df.business_id == row['business_id'], 'latest_3m_reviews_count'] = review_num_3m\n",
    "    else:\n",
    "        print(\"error: business_id mismatch.\")\n",
    "        \n",
    "bus_df['review_count'].head()\n",
    "\n",
    "# Check:\n",
    "# --6MefnULPED_I942VcFNA      24\n",
    "# --9e1ONYQuAa-CB_Rrw7Tw    1311\n",
    "# --DaPTJW3-tB1vP-PfdTEg      32\n",
    "# --FBCX-N37CMYDfs790Bnw      88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 1000)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# #print(str(bus_df.loc[bus_df.business_id == '--6MefnULPED_I942VcFNA', 'reviews']))\n",
    "# bus_df['reviews'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "--6MefnULPED_I942VcFNA     1\n",
       "--9e1ONYQuAa-CB_Rrw7Tw    43\n",
       "--DaPTJW3-tB1vP-PfdTEg     2\n",
       "--FBCX-N37CMYDfs790Bnw     4\n",
       "--GM_ORV2cYS-h38DSaCLw     1\n",
       "Name: latest_3m_reviews_count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus_df['latest_3m_reviews_count'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bus_df = bus_df.drop('latest_3m_reviews', axis=1)\n",
    "bus_df=bus_df.rename(columns = {'reviews':'latest_3m_reviews'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newfile_path = \"/Users/xinpeilin/Documents/CS_Learning/Data_Mining/Project/joined_3mReviews_df.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=161549122...\n",
      "writing bytes [0, 161549122)... done.\n"
     ]
    }
   ],
   "source": [
    "pickle_dump(bus_df, newfile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pickle_load(newfile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_count</th>\n",
       "      <th>latest_3m_reviews_count</th>\n",
       "      <th>latest_3m_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>--6MefnULPED_I942VcFNA</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>They have the best Chinese BBQ Pork (Char Siu)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--9e1ONYQuAa-CB_Rrw7Tw</th>\n",
       "      <td>1280</td>\n",
       "      <td>43</td>\n",
       "      <td>Exceptional...exceptional steakhouse!! Ordered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--DaPTJW3-tB1vP-PfdTEg</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>Sunnyside grill is sort of american diner sort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--FBCX-N37CMYDfs790Bnw</th>\n",
       "      <td>84</td>\n",
       "      <td>4</td>\n",
       "      <td>Moved to a neighborhood right by this restaura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--GM_ORV2cYS-h38DSaCLw</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Screwed up my order. Had to wait for a second ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        review_count  latest_3m_reviews_count  \\\n",
       "--6MefnULPED_I942VcFNA            22                        1   \n",
       "--9e1ONYQuAa-CB_Rrw7Tw          1280                       43   \n",
       "--DaPTJW3-tB1vP-PfdTEg            29                        2   \n",
       "--FBCX-N37CMYDfs790Bnw            84                        4   \n",
       "--GM_ORV2cYS-h38DSaCLw             5                        1   \n",
       "\n",
       "                                                        latest_3m_reviews  \n",
       "--6MefnULPED_I942VcFNA  They have the best Chinese BBQ Pork (Char Siu)...  \n",
       "--9e1ONYQuAa-CB_Rrw7Tw  Exceptional...exceptional steakhouse!! Ordered...  \n",
       "--DaPTJW3-tB1vP-PfdTEg  Sunnyside grill is sort of american diner sort...  \n",
       "--FBCX-N37CMYDfs790Bnw  Moved to a neighborhood right by this restaura...  \n",
       "--GM_ORV2cYS-h38DSaCLw  Screwed up my order. Had to wait for a second ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['review_count','latest_3m_reviews_count','latest_3m_reviews']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latest_3m_reviews</th>\n",
       "      <th>is_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>--6MefnULPED_I942VcFNA</th>\n",
       "      <td>They have the best Chinese BBQ Pork (Char Siu)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--9e1ONYQuAa-CB_Rrw7Tw</th>\n",
       "      <td>Exceptional...exceptional steakhouse!! Ordered...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--DaPTJW3-tB1vP-PfdTEg</th>\n",
       "      <td>Sunnyside grill is sort of american diner sort...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--FBCX-N37CMYDfs790Bnw</th>\n",
       "      <td>Moved to a neighborhood right by this restaura...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--GM_ORV2cYS-h38DSaCLw</th>\n",
       "      <td>Screwed up my order. Had to wait for a second ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        latest_3m_reviews  \\\n",
       "--6MefnULPED_I942VcFNA  They have the best Chinese BBQ Pork (Char Siu)...   \n",
       "--9e1ONYQuAa-CB_Rrw7Tw  Exceptional...exceptional steakhouse!! Ordered...   \n",
       "--DaPTJW3-tB1vP-PfdTEg  Sunnyside grill is sort of american diner sort...   \n",
       "--FBCX-N37CMYDfs790Bnw  Moved to a neighborhood right by this restaura...   \n",
       "--GM_ORV2cYS-h38DSaCLw  Screwed up my order. Had to wait for a second ...   \n",
       "\n",
       "                        is_open  \n",
       "--6MefnULPED_I942VcFNA        1  \n",
       "--9e1ONYQuAa-CB_Rrw7Tw        1  \n",
       "--DaPTJW3-tB1vP-PfdTEg        1  \n",
       "--FBCX-N37CMYDfs790Bnw        1  \n",
       "--GM_ORV2cYS-h38DSaCLw        1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = df[['latest_3m_reviews', 'is_open']].copy()\n",
    "reviews_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tfidf unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X= reviews_df['latest_3m_reviews']\n",
    "Y= np.asarray(reviews_df['is_open'], dtype='bool')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=.80)\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf = True)\n",
    "vectorizer.fit(X_train)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "# vocabulary_list = list(zip( vectorizer.vocabulary_.keys(), binary_vectorizer.vocabulary_.values()) )\n",
    "# vocabulary_list[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aligot',\n",
       " 'alihan',\n",
       " 'aliiiiive',\n",
       " 'aliitle',\n",
       " 'alike',\n",
       " 'alikes',\n",
       " 'alil',\n",
       " 'alimentaire',\n",
       " 'alimentary',\n",
       " 'alimentation']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names) #109107\n",
    "feature_names[5000:5010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = vectorizer.transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<38794x109107 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7686915 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Accuracy = 0.788\n",
      "Area under the ROC curve on test data (LogisticRegression) = 0.727\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, Y_train)\n",
    "LR_accuracy = metrics.accuracy_score(model.predict(X_test_tfidf), Y_test)\n",
    "print(\"LR Accuracy = %.3f\" % LG_accuracy)\n",
    "print(\"Area under the ROC curve on test data (LogisticRegression) = %.3f\" % metrics.roc_auc_score(model.predict(X_test_tfidf), Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy = 0.774\n",
      "Area under the ROC curve on test data (SVM) = 0.670\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "lsvc_model = LinearSVC()\n",
    "lsvc_model.fit(X_train_tfidf, Y_train)\n",
    "SVM_accuracy = metrics.accuracy_score(lsvc_model.predict(X_test_tfidf), Y_test)\n",
    "print(\"SVM Accuracy = %.3f\" % SVM_accuracy)\n",
    "print(\"Area under the ROC curve on test data (SVM) = %.3f\" % metrics.roc_auc_score(lsvc_model.predict(X_test_tfidf), Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tfidf trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), sublinear_tf = True)\n",
    "vectorizer.fit(X_train)\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23 in',\n",
       " '23 in the',\n",
       " '23 including',\n",
       " '23 including the',\n",
       " '23 ish',\n",
       " '23 ish 25',\n",
       " '23 ish dinner',\n",
       " '23 it',\n",
       " '23 it an',\n",
       " '23 it included']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names) #10,543,718\n",
    "feature_names[50000:50010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf_trigram = vectorizer.transform(X_train)\n",
    "X_test_tfidf_trigram = vectorizer.transform(X_test)\n",
    "model.fit(X_train_tfidf_trigram, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Accuracy = 0.773\n",
      "Area under the ROC curve on test data (LogisticRegression, trigram) = 0.807\n"
     ]
    }
   ],
   "source": [
    "LR_accuracy_trigram = metrics.accuracy_score(model.predict(X_test_tfidf_trigram), Y_test)\n",
    "print(\"LR Accuracy = %.3f\" % LR_accuracy_trigram)\n",
    "print (\"Area under the ROC curve on test data (LogisticRegression, trigram) = %.3f\" % metrics.roc_auc_score(model.predict(X_test_tfidf_trigram), Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03259681 -0.05354299  0.0013548  ..., -0.02637974 -0.02637974\n",
      "  -0.02637974]]\n"
     ]
    }
   ],
   "source": [
    "# https://medium.com/@aneesha/visualising-top-features-in-linear-svm-with-scikit-learn-and-matplotlib-3454ab18a14d\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "top_positive_feature_list = []\n",
    "top_negative_feature_list = []\n",
    "\n",
    "def get_coefficeints(classifier, feature_names, top_features):\n",
    "    coef = classifier.coef_.ravel()\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "    add_count_for_features(top_positive_coefficients, top_negative_coefficients, feature_names)\n",
    "    # top_positive_feature_list = []\n",
    "    # top_negative_feature_list = []\n",
    "    for i in top_positive_coefficients[::-1]:\n",
    "        top_positive_feature_list.append(feature_names[i]) \n",
    "    for i in top_negative_coefficients[::-1]:\n",
    "        top_negative_feature_list.append(feature_names[i])\n",
    "\n",
    "    # print (\"top_positive_feature_list:\", top_positive_feature_list)\n",
    "    # print (\"top_negative_feature_list:\", top_negative_feature_list)\n",
    "    return coef, top_coefficients\n",
    "\n",
    "    \n",
    "def plot_coefficients(classifier, feature_names, top_features=20):\n",
    "    # create plot\n",
    "    coef, top_coefficients = get_coefficeints(classifier, feature_names, top_features)\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    colors = ['red' if c < 0 else 'blue' for c in coef[top_coefficients]]\n",
    "    plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(1, 1 + 2 * top_features), feature_names[top_coefficients], rotation=60, ha='right')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def add_count_for_features(top_positive_coefficients, top_negative_coefficients, feature_names):\n",
    "    for i in top_positive_coefficients[::-1]:\n",
    "        try: \n",
    "            total_positive_feature_count[feature_names[i]] += 1\n",
    "        except:\n",
    "            total_positive_feature_count[feature_names[i]] = 1\n",
    "            \n",
    "    for i in top_negative_coefficients[::-1]:\n",
    "        try: \n",
    "            total_negative_feature_count[feature_names[i]] += 1\n",
    "        except:\n",
    "            total_negative_feature_count[feature_names[i]] = 1\n",
    "            \n",
    "\n",
    "for i in range(len(cluster_eps01_models)):\n",
    "    X, Y = feature_target_seperator(cluster_eps01_dfs[i])\n",
    "    cv = CountVectorizer()\n",
    "    cv.fit(X)\n",
    "    plot_coefficients(cluster_eps01_models[i], cv.get_feature_names(), top_features=20)\n",
    "\n",
    "# print (total_positive_feature_count)\n",
    "# print (total_negative_feature_count)\n",
    "# plot_coefficients(cluster0_LinearSVC_model, cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Create column ['reviews'] in bus_df, having the latest 4 months reviews. Update bus_df['review_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "--6MefnULPED_I942VcFNA      22\n",
       "--9e1ONYQuAa-CB_Rrw7Tw    1280\n",
       "--DaPTJW3-tB1vP-PfdTEg      29\n",
       "--FBCX-N37CMYDfs790Bnw      84\n",
       "--GM_ORV2cYS-h38DSaCLw       5\n",
       "Name: review_count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#instances_num = 48493\n",
    "bus_df['latest_4m_reviews'] = \"\"\n",
    "bus_df['latest_4m_reviews_count'] = 0\n",
    "for index, row in bus_df.iterrows():\n",
    "    if row['business_id'] in review_d:\n",
    "        text = \"\"\n",
    "        review_num = 0\n",
    "        review_num_4m = 0\n",
    "        last_date = last_review_date(review_d, row['business_id'])\n",
    "        for key, value in review_d[row['business_id']].items():\n",
    "            for review in value:\n",
    "                review_num += 1\n",
    "                if get_time(key) > (get_time(last_date) - FourMonths):\n",
    "                    text = text + review + \" \"\n",
    "                    review_num_4m += 1\n",
    "        bus_df.loc[bus_df.business_id == row['business_id'], 'review_count'] = review_num\n",
    "        bus_df.loc[bus_df.business_id == row['business_id'], 'latest_4m_reviews'] = text\n",
    "        bus_df.loc[bus_df.business_id == row['business_id'], 'latest_4m_reviews_count'] = review_num_4m\n",
    "    else:\n",
    "        print(\"error: business_id mismatch.\")\n",
    "        \n",
    "bus_df['review_count'].head()\n",
    "\n",
    "# Check:\n",
    "# --6MefnULPED_I942VcFNA      24\n",
    "# --9e1ONYQuAa-CB_Rrw7Tw    1311\n",
    "# --DaPTJW3-tB1vP-PfdTEg      32\n",
    "# --FBCX-N37CMYDfs790Bnw      88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_count</th>\n",
       "      <th>latest_4m_reviews_count</th>\n",
       "      <th>latest_4m_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>--6MefnULPED_I942VcFNA</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>The incredibly rude woman behind the cashier w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--9e1ONYQuAa-CB_Rrw7Tw</th>\n",
       "      <td>1280</td>\n",
       "      <td>60</td>\n",
       "      <td>Exceptional...exceptional steakhouse!! Ordered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--DaPTJW3-tB1vP-PfdTEg</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>Sunnyside grill is sort of american diner sort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--FBCX-N37CMYDfs790Bnw</th>\n",
       "      <td>84</td>\n",
       "      <td>5</td>\n",
       "      <td>Happy Hour has to many rules, certain drinks a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--GM_ORV2cYS-h38DSaCLw</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Screwed up my order. Had to wait for a second ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        review_count  latest_4m_reviews_count  \\\n",
       "--6MefnULPED_I942VcFNA            22                        2   \n",
       "--9e1ONYQuAa-CB_Rrw7Tw          1280                       60   \n",
       "--DaPTJW3-tB1vP-PfdTEg            29                        2   \n",
       "--FBCX-N37CMYDfs790Bnw            84                        5   \n",
       "--GM_ORV2cYS-h38DSaCLw             5                        1   \n",
       "\n",
       "                                                        latest_4m_reviews  \n",
       "--6MefnULPED_I942VcFNA  The incredibly rude woman behind the cashier w...  \n",
       "--9e1ONYQuAa-CB_Rrw7Tw  Exceptional...exceptional steakhouse!! Ordered...  \n",
       "--DaPTJW3-tB1vP-PfdTEg  Sunnyside grill is sort of american diner sort...  \n",
       "--FBCX-N37CMYDfs790Bnw  Happy Hour has to many rules, certain drinks a...  \n",
       "--GM_ORV2cYS-h38DSaCLw  Screwed up my order. Had to wait for a second ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus_df[['review_count', 'latest_4m_reviews_count', 'latest_4m_reviews']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=196054111...\n",
      "writing bytes [0, 196054111)... done.\n"
     ]
    }
   ],
   "source": [
    "pickle_dump(bus_df, \"/Users/xinpeilin/Documents/CS_Learning/Data_Mining/Project/joined_4mReviews_df.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latest_4m_reviews</th>\n",
       "      <th>is_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>--6MefnULPED_I942VcFNA</th>\n",
       "      <td>The incredibly rude woman behind the cashier w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--9e1ONYQuAa-CB_Rrw7Tw</th>\n",
       "      <td>Exceptional...exceptional steakhouse!! Ordered...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--DaPTJW3-tB1vP-PfdTEg</th>\n",
       "      <td>Sunnyside grill is sort of american diner sort...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--FBCX-N37CMYDfs790Bnw</th>\n",
       "      <td>Happy Hour has to many rules, certain drinks a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--GM_ORV2cYS-h38DSaCLw</th>\n",
       "      <td>Screwed up my order. Had to wait for a second ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        latest_4m_reviews  \\\n",
       "--6MefnULPED_I942VcFNA  The incredibly rude woman behind the cashier w...   \n",
       "--9e1ONYQuAa-CB_Rrw7Tw  Exceptional...exceptional steakhouse!! Ordered...   \n",
       "--DaPTJW3-tB1vP-PfdTEg  Sunnyside grill is sort of american diner sort...   \n",
       "--FBCX-N37CMYDfs790Bnw  Happy Hour has to many rules, certain drinks a...   \n",
       "--GM_ORV2cYS-h38DSaCLw  Screwed up my order. Had to wait for a second ...   \n",
       "\n",
       "                        is_open  \n",
       "--6MefnULPED_I942VcFNA        1  \n",
       "--9e1ONYQuAa-CB_Rrw7Tw        1  \n",
       "--DaPTJW3-tB1vP-PfdTEg        1  \n",
       "--FBCX-N37CMYDfs790Bnw        1  \n",
       "--GM_ORV2cYS-h38DSaCLw        1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pickle_load(\"/Users/xinpeilin/Documents/CS_Learning/Data_Mining/Project/joined_4mReviews_df.p\")\n",
    "reviews_df = df[['latest_4m_reviews', 'is_open']].copy()\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X= reviews_df['latest_4m_reviews']\n",
    "Y= np.asarray(reviews_df['is_open'], dtype='bool')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=.80)\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf = True)\n",
    "vectorizer.fit(X_train)\n",
    "X_train_tfidf = vectorizer.transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Features: 120 days reviews, Model: Logistic Regression>\n",
      "Accuracy = 0.794\n",
      "Area under the ROC curve on test data = 0.730\n"
     ]
    }
   ],
   "source": [
    "LR_model = LogisticRegression()\n",
    "LR_model.fit(X_train_tfidf, Y_train)\n",
    "LR_accuracy = metrics.accuracy_score(LR_model.predict(X_test_tfidf), Y_test)\n",
    "print(\"<Features: 120 days reviews, Model: Logistic Regression>\")\n",
    "print(\"Accuracy = %.3f\" % LR_accuracy)\n",
    "print(\"Area under the ROC curve on test data = %.3f\" % metrics.roc_auc_score(LR_model.predict(X_test_tfidf), Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tfidf = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation AUC: 0.76 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(LR_model, X_tfidf, Y, cv=10, scoring='roc_auc')\n",
    "print(\"Cross Validation AUC: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "#4 months, LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_wcount = count_vectorizer.transform(X_train)\n",
    "X_test_wcount = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6642)\t3\n",
      "  (0, 10772)\t1\n",
      "  (0, 16358)\t1\n",
      "  (0, 17974)\t1\n",
      "  (0, 25937)\t1\n",
      "  (0, 30275)\t1\n",
      "  (0, 33620)\t1\n",
      "  (0, 37106)\t1\n",
      "  (0, 37942)\t1\n",
      "  (0, 41061)\t1\n",
      "  (0, 41230)\t2\n",
      "  (0, 41693)\t1\n",
      "  (0, 50086)\t1\n",
      "  (0, 50138)\t1\n",
      "  (0, 51477)\t1\n",
      "  (0, 53652)\t1\n",
      "  (0, 55111)\t2\n",
      "  (0, 55178)\t1\n",
      "  (0, 55226)\t1\n",
      "  (0, 55317)\t1\n",
      "  (0, 60331)\t2\n",
      "  (0, 61684)\t1\n",
      "  (0, 62114)\t1\n",
      "  (0, 64507)\t1\n",
      "  (0, 66373)\t1\n",
      "  :\t:\n",
      "  (0, 91246)\t1\n",
      "  (0, 92716)\t1\n",
      "  (0, 93263)\t1\n",
      "  (0, 98881)\t1\n",
      "  (0, 99677)\t1\n",
      "  (0, 100457)\t1\n",
      "  (0, 100520)\t1\n",
      "  (0, 100539)\t1\n",
      "  (0, 102403)\t1\n",
      "  (0, 104183)\t3\n",
      "  (0, 104203)\t6\n",
      "  (0, 104410)\t1\n",
      "  (0, 104515)\t3\n",
      "  (0, 104539)\t1\n",
      "  (0, 105351)\t2\n",
      "  (0, 107240)\t1\n",
      "  (0, 107770)\t1\n",
      "  (0, 107809)\t1\n",
      "  (0, 108045)\t1\n",
      "  (0, 110002)\t1\n",
      "  (0, 113254)\t1\n",
      "  (0, 114761)\t1\n",
      "  (0, 115020)\t1\n",
      "  (0, 115496)\t1\n",
      "  (0, 116740)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X_train_wcount[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Features: 120 days reviews, Model: MultinomialNB>\n",
      "Accuracy = 0.778\n",
      "Area under the ROC curve on test data = 0.673\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train_wcount, Y_train)\n",
    "NB_accuracy = metrics.accuracy_score(NB_model.predict(X_test_wcount), Y_test)\n",
    "print(\"<Features: 120 days reviews, Model: MultinomialNB>\")\n",
    "print(\"Accuracy = %.3f\" % NB_accuracy)\n",
    "print(\"Area under the ROC curve on test data = %.3f\" % metrics.roc_auc_score(NB_model.predict(X_test_wcount), Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Features: 120 days reviews, Model: BernoulliNB>\n",
      "Accuracy = 0.517\n",
      "Area under the ROC curve on test data = 0.537\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "NB_model = BernoulliNB()\n",
    "NB_model.fit(X_train_wcount, Y_train)\n",
    "NB_accuracy = metrics.accuracy_score(NB_model.predict(X_test_wcount), Y_test)\n",
    "print(\"<Features: 120 days reviews, Model: BernoulliNB>\")\n",
    "print(\"Accuracy = %.3f\" % NB_accuracy)\n",
    "print(\"Area under the ROC curve on test data = %.3f\" % metrics.roc_auc_score(NB_model.predict(X_test_wcount), Y_test))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
